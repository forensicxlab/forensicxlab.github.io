"use strict";(self.webpackChunkexhume=self.webpackChunkexhume||[]).push([[3724],{339:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/2-6b7a445d035f2148cf99a5c192b2753c.png"},940:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/5-fd094b737b9ffe1c697fe2634ee0fa37.png"},2190:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/7-d14b206fa13c55232ed8c8ee341c6b56.png"},2565:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/4-8b476a211c50751810243d1dd1066be3.png"},2698:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var i=n(9940),s=n(4848),a=n(8453);const r={slug:"exhume-aff4",title:"\ud83d\udd26 Debunking the Cellebrite (MacQuisition) Advanced Forensics File Format Version 4 (AFF4) implementation",authors:["k1nd0ne"],tags:["Thanatology","Exhume","Digital Forensics","AFF4"],draft:!1},o=void 0,l={authorsImageUrls:[void 0]},d=[{value:"The information Turtle",id:"the-information-turtle",level:2},{value:"The Map",id:"the-map",level:2},{value:"The Cellebrite/MacQuisition divergence",id:"the-cellebritemacquisition-divergence",level:3},{value:"The <code>idx</code> table next to it",id:"the-idx-table-next-to-it",level:3},{value:"The Segments",id:"the-segments",level:2},{value:"The Cellebrite/MacAquisition divergence",id:"the-cellebritemacaquisition-divergence",level:3},{value:"How to read data",id:"how-to-read-data",level:2},{value:"Reading N bytes at virtual offset V",id:"reading-n-bytes-at-virtual-offset-v",level:3}];function c(e){const t={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:["In the objective of implementing the modern Apple File System (APFS) module of the ",(0,s.jsx)(t.code,{children:"[exhume"})," toolkit](",(0,s.jsx)(t.a,{href:"https://www.forensicxlab.com/docs/exhume",children:"https://www.forensicxlab.com/docs/exhume"}),"), a test disk image from a recent macOS system was required. In practice, acquiring ",(0,s.jsx)(t.em,{children:"physical"})," data from modern Apple hardware (especially with T2 / security constraints) quickly narrows the tooling landscape, and ",(0,s.jsx)(t.strong,{children:"Cellebrite BlackLight / MacQuisition"})," seems to be the default choice."]}),"\n",(0,s.jsxs)(t.p,{children:["After acquiring disk image of a modern Apple computer, the output format was ",(0,s.jsx)(t.strong,{children:"AFF4"})," (Advanced Forensics File Format v4). After not being able to convert this image to a raw disk image on my operating system and, in a quest to make the digital forensics investigation platform agnostic, the next step was obvious: add AFF4 support to exhume_body and make it reliable enough to feed an APFS parser."]}),"\n",(0,s.jsxs)(t.p,{children:["In this blog post, I describe that journey and the key findings along the way. The important part is this: ",(0,s.jsx)(t.strong,{children:"MacQuisition produces an AFF4 that strongly diverges from what most public AFF4 descriptions (and many OSS parsers) that I have found assume"}),", which makes existing implementations fail or perform poorly."]}),"\n",(0,s.jsx)(t.p,{children:"Let\u2019s solve this properly."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h1,{id:"motivation",children:"Motivation"}),"\n",(0,s.jsx)(t.p,{children:"Before going down the rabbit hole, I tried the obvious shortcut: export the AFF4 to a raw disk image and feed that to the APFS parser."}),"\n",(0,s.jsxs)(t.p,{children:["My first attempt was to export to raw with ",(0,s.jsx)(t.a,{href:"https://aff4-imager.readthedocs.io/en/latest/index.html",children:"aff4imager"})]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"aff4imager -e 'aff4://f47e5cb5-c0e1-4301-b382-67f73f3b02ce' --export_dir test/ ~/IMAGE.aff4\n"})}),"\n",(0,s.jsx)(t.p,{children:"However, the tool output is the following:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"Compression method https://code.google.com/p/lz4/ is not supported by this implementation.\nCompression method https://code.google.com/p/lz4/ is not supported by this implementation.\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Well, that\u2019s\u2026 not right and I couldn't mount this aff4 image on my mac. And for this injustice, I redirected my full focus onto ",(0,s.jsx)(t.strong,{children:"this specific AFF4 implementation"}),". The following sections describe the journey and how to reliably read bytes from this MacQuisition-produced AFF4 starting from scratch. Note that my implementation needs to be tested on other images in order to make it more robust. This is not an academic paper, the next sections contain the information and conceptes I have learned and understood and therefore subjective. It could lack some information. Make sure to send me a message if some of what you are reading needs to be modified!"]}),"\n",(0,s.jsx)(t.h1,{id:"background-on-aff4",children:"Background on AFF4"}),"\n",(0,s.jsxs)(t.p,{children:["AFF4 (Advanced Forensics Format Version 4) is not just a disk image format like we saw with ",(0,s.jsx)(t.a,{href:"https://www.forensicxlab.com/blog/ewf",children:"EWF"}),". It is a ",(0,s.jsx)(t.strong,{children:"container + data model"})," designed for forensic acquisition workflows."]}),"\n",(0,s.jsx)(t.p,{children:'AFF version 4 was completed in 2009 by Michael Cohen, Simson Garfinkel, and Bradley Schatz. The design was introduced in their paper: "Extending the advanced forensic format to accommodate multiple data sources, logical evidence, arbitrary information and forensic workflow," published in Digital Investigation 6 (2009), S57\u2013S68. That publication shipped alongside an early reference implementation written in Python. The version later made available via aff4.org is a separate, open-source reimplementation intended to serve as a general-purpose AFF4 library.'}),"\n",(0,s.jsx)(t.p,{children:'A useful snapshot of the motivation and historical context appears in a 2010 Digital Investigation article (vol. 7) titled "Hash based disk imaging using AFF4." The authors contrast earlier approaches to forensic imaging\u2014first, raw \u201cbit-for-bit\u201d acquisition (often described as dd images), and then block-based compression methods that improved storage efficiency but could increase acquisition time. They position AFF4 as a "third generation" forensic format: one that brings multiple image streams, arbitrary metadata, and storage virtualization directly into the file format itself.'}),"\n",(0,s.jsx)(t.p,{children:"Since, some digital forensics vendors were also able to develop their own implementations of AFF4 acquisition, and not a lot of documentation on the evolutions of the format since 2010 is available online."}),"\n",(0,s.jsx)(t.h1,{id:"aff4-high-level-structure-overview",children:"AFF4 high-level structure overview"}),"\n",(0,s.jsxs)(t.p,{children:['As usual, let\'s start simple (and therefore in a vulgarised way) to describe an AFF4 image. At its base, AFF4 is just a ZIP file using the Zip64 extension. This is the main "container" for storing ',(0,s.jsx)(t.strong,{children:"streams"})," and ",(0,s.jsx)(t.strong,{children:"metadata"})," files."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(8360).A+"",title:"High level overview",width:"2318",height:"1432"})}),"\n",(0,s.jsxs)(t.p,{children:['Inside the AFF4 container directory structure, we can find a file named "information.turtle". Unlike the EWF format that we have studied in earlier blog posts, AFF4 doesn\'t use fixed binary headers for metadata. Instead, it is using the Resource Description Framework (RDF) serialised as "Turtle" (Terse RDF Triple Language). The "information.turtle" zip member contains the metadata needed to describe the layout of the AFF4 image. The metadata stored inside the information turtle informs our tool about record ',(0,s.jsx)(t.strong,{children:"object"})," types, attributes (sizes, chunking parameters, timestamps, tool info), and relationships between ",(0,s.jsx)(t.strong,{children:"objects"}),". I will dive into more details later."]}),"\n",(0,s.jsxs)(t.p,{children:["Let's talk vocabulary! in AFF4, each \"",(0,s.jsx)(t.strong,{children:"Object"}),'" is identified with a unique ',(0,s.jsx)(t.strong,{children:"URN"})," (Uniform Resource Name)."]}),"\n",(0,s.jsxs)(t.p,{children:["In the context of this blog post, I divide AFF4 Objects into three categories: The ",(0,s.jsx)(t.strong,{children:"Evidence"})," object(s), the ",(0,s.jsx)(t.strong,{children:"Map"})," object(s) and the ",(0,s.jsx)(t.strong,{children:"Image"})," object(s). The Map & Image are not stored as one blob, AFF4 models the evidence bytes as a sequential, addressable flow of bytes. We will refer to them as ",(0,s.jsx)(t.strong,{children:"MapStream"})," and ",(0,s.jsx)(t.strong,{children:"ImageStream"})]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["The ",(0,s.jsx)(t.strong,{children:"Evidence"})," object is the thing we want to mount/read: for example, a disk image."]}),"\n",(0,s.jsxs)(t.li,{children:["The ",(0,s.jsx)(t.strong,{children:"MapStream"}),' object provides the necessary information to obtain one logical "view" of an acquired disk image, a partition image, a file, a carved artefact, etc.']}),"\n",(0,s.jsxs)(t.li,{children:["The ",(0,s.jsx)(t.strong,{children:"ImageStream"})," object is the backing storage that provides the bytes for one or more views."]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["Note that we ",(0,s.jsx)(t.strong,{children:"can have multiple ImageStream objects"})," if we perform the acquisition of multiple sources. For example, we could acquire a disk image into a first image object and the memory of the machine in another one."]}),"\n",(0,s.jsx)(t.h2,{id:"the-information-turtle",children:"The information Turtle"}),"\n",(0,s.jsxs)(t.p,{children:["The information turtle gives us the important metadata between the acquired Evidence(s) layout and the generated logical AFF4 layout. This is not optional decoration: readers ",(0,s.jsx)(t.em,{children:"must"})," use it to interpret the container like mentioned in the ",(0,s.jsx)(t.a,{href:"https://www.sciencedirect.com/science/article/pii/S1742287609000401",children:"main article about the subject"}),". Let's take a look at the information turtle of the Cellebrite/MacQuisition produced AFF4 image."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(2565).A+"",title:"Information Turtle Example",width:"2152",height:"1175"})}),"\n",(0,s.jsxs)(t.p,{children:["In this example, a total of ",(0,s.jsx)(t.strong,{children:"242837545 blocks"})," of ",(0,s.jsx)(t.strong,{children:"4096 bytes each"})," were acquired and are representing an ",(0,s.jsx)(t.strong,{children:"APFSContainerImage"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["In the AFF4 world, the acquired blocks from the source evidence are concatenated into ",(0,s.jsx)(t.strong,{children:"Chunks"}),". In our example, the size of a chunk is 32768 bytes (= 8 * 4096 = 8 blocks). Multiple chunks are stored into ",(0,s.jsx)(t.strong,{children:"Segments"}),". In our example, the number of chunk in one Segment is 1024. In AFF4 each Segments are backed up as a file in the container (ZIP) for a total size of 53861023744 bytes (~50Gb)."]}),"\n",(0,s.jsx)(t.p,{children:"To know the number of segments, we can use the following math: number_of_segments = total_size / size_of_one_segment."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(7975).A+"",title:"Map target dictionnary",width:"3662",height:"2257"})}),"\n",(0,s.jsx)(t.p,{children:"In our case: number_of_segments = 53861023744 / (1024 * 32768) = 1605 Segments !"}),"\n",(0,s.jsxs)(t.p,{children:['That is great, we have the necessary metadata to retrieve the information about the Segments, the blocks and the URNs used to store the bytes. But now, how can I extract 512 bytes of data from offset 0x12502 "from the point of view" of the original evidence? AFF4 doesn\'t store sparse data when using the Map object during acquisition, so it needs to keep track of the original acquired offsets and the image. We still need the ',(0,s.jsx)(t.strong,{children:"Map"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"the-map",children:"The Map"}),"\n",(0,s.jsxs)(t.p,{children:["The Map Object allows us to know the mapping between the acquired image and it's logical representation. The map basically allows us to perform: \"",(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"If I want 512 bytes from offset 0x1215 in the original (virtual) aquired image, I need to look at offset 0x.... in the AFF4 ImageStream X"})}),'"']}),"\n",(0,s.jsx)(t.p,{children:"Many published examples show that the MapStream is stored in the AFF4 container (ZIP) as two records:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"The target dictionary"}),": Association between an ID and the name of the byte stream."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"The intervals list"}),": A (originally) text-map composed of multiple records. Each record holds the following:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Virtual offset: virtual/logical start offset in the map\u2019s logical stream;"}),"\n",(0,s.jsx)(t.li,{children:"Length: number of bytes in this extent (the run length);"}),"\n",(0,s.jsx)(t.li,{children:"Target offset: start offset in the backing target stream where those bytes come from;"}),"\n",(0,s.jsx)(t.li,{children:"Index: which target stream (lookup in the map\u2019s /idx table)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"In the case of our Cellebrite/MacQuisition AFF4 container:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["The target dictionary is stored in the ZipFile record: aff4://1ddcf287-f499-492a-ab06-7edec982b094/",(0,s.jsx)(t.strong,{children:"idx"})]}),"\n",(0,s.jsxs)(t.li,{children:["The intervals list is stored in the ZipFile record: aff4://1ddcf287-f499-492a-ab06-7edec982b094/",(0,s.jsx)(t.strong,{children:"map"})]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"the-cellebritemacquisition-divergence",children:"The Cellebrite/MacQuisition divergence"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"The following was not documented anywhere I've looked online. This is based on the deep inspection of my acquisition image."})}),"\n",(0,s.jsxs)(t.p,{children:['MacQuisition\u2019s AFF4 map stream is not a line-oriented "text map". It is a packed binary array of fixed-size records. Each record is ',(0,s.jsx)(t.strong,{children:"28 bytes"}),", little-endian:"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(2190).A+"",title:"Map records",width:"1748",height:"1014"})}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Byte range (inclusive-exclusive)"}),(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Size"}),(0,s.jsx)(t.th,{children:"Type (LE)"}),(0,s.jsx)(t.th,{children:"Field"}),(0,s.jsx)(t.th,{children:"Meaning"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"0..8"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"8"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u64"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"virtual_offset"})}),(0,s.jsxs)(t.td,{children:["Start offset in the ",(0,s.jsx)(t.strong,{children:"virtual image"})," (the reconstructed address space)"]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"8..16"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"8"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u64"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"extent_len"})}),(0,s.jsx)(t.td,{children:"Length in bytes of this mapping run (0 may be used as a sentinel/hole marker)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"16..24"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"8"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u64"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"target_offset"})}),(0,s.jsxs)(t.td,{children:["Offset in the ",(0,s.jsx)(t.strong,{children:"target stream"})," where data is sourced from"]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"24..28"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"4"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u32"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"target_index"})}),(0,s.jsxs)(t.td,{children:["Index into the adjacent ",(0,s.jsx)(t.strong,{children:"idx table"})," (string table of target URIs)"]})]})]})]}),"\n",(0,s.jsx)(t.p,{children:"For a given record:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The virtual range covered is:"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.code,{children:"virtual_offset .. virtual_offset + extent_len"})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The corresponding bytes are read from:"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"target_uri[target_index]"})," at offset ",(0,s.jsx)(t.code,{children:"target_offset"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.h3,{id:"the-idx-table-next-to-it",children:["The ",(0,s.jsx)(t.code,{children:"idx"})," table next to it"]}),"\n",(0,s.jsxs)(t.p,{children:["The map does not store the target URIs inline. It is using the member next to it (",(0,s.jsx)(t.code,{children:".../idx"}),") which is a ",(0,s.jsx)(t.strong,{children:"NUL-separated string table"}),":"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Split by ",(0,s.jsx)(t.code,{children:"0x00"})]}),"\n",(0,s.jsxs)(t.li,{children:["Each string is a target URI (e.g. ",(0,s.jsx)(t.code,{children:"aff4://.../data"}),")"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"target_index"})," in the 28-byte record selects one of these strings"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This reduces map size significantly when many records refer to the same target stream."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(339).A+"",title:"Map target dictionnary",width:"2490",height:"1596"})}),"\n",(0,s.jsx)(t.h2,{id:"the-segments",children:"The Segments"}),"\n",(0,s.jsx)(t.p,{children:"In the AFF4 world, and specifically in our case, each segment can be backed by a file in the AFF4 container (ZIP).\nFor example:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"aff4://1ddcf287-f499-492a-ab06-7edec982b094/00000001 contains the segment number 1"}),"\n",(0,s.jsx)(t.li,{children:"aff4://1ddcf287-f499-492a-ab06-7edec982b094/00000002 contains the segment number 2"}),"\n",(0,s.jsx)(t.li,{children:"etc.."}),"\n"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"In our case we have 1605 segments, so it will go from aff4://1ddcf287-f499-492a-ab06-7edec982b094/00000001 to aff4://1ddcf287-f499-492a-ab06-7edec982b094/00001605"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"the-cellebritemacaquisition-divergence",children:"The Cellebrite/MacAquisition divergence"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"The following is not documented anywhere I've looked online. This is based on the inspection of my acquisition image."})}),"\n",(0,s.jsx)(t.p,{children:"If you come back to the metadata of the information turtle showed, you can see a property named:"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.code,{children:"aff4:compressionMethod <https://code.google.com/p/lz4/> ;"})}),"\n",(0,s.jsxs)(t.p,{children:["That means every chunk is compressed before being stored in the segments. ",(0,s.jsx)(t.strong,{children:"So we actually have segments that can contain compressed chunks using the lz4 compression method"})]}),"\n",(0,s.jsxs)(t.p,{children:["In the case of Cellebrite/MacAquisition, and in order to keep track of the variable lengths and offsets of each compressed chunks, they also stores an ",(0,s.jsx)(t.strong,{children:"index"}),' file alongside each segment member. These "segments indexes" are composed of ',(0,s.jsx)(t.strong,{children:"12-byte entries"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"Each entry is 12 bytes, little-endian, and it encodes (compressed offset, compressed length) for one chunk inside the corresponding segment member\u2019s payload."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Byte range (inclusive-exclusive)"}),(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Size"}),(0,s.jsx)(t.th,{children:"Type (LE)"}),(0,s.jsx)(t.th,{children:"Field"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"0..4"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"4"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u32"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"lo"})}),(0,s.jsxs)(t.td,{children:["Low 32 bits of the chunk blob offset (",(0,s.jsx)(t.code,{children:"c_off"}),") within the ",(0,s.jsx)(t.strong,{children:"segment member payload"})]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"4..8"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"4"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u32"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"hi"})}),(0,s.jsxs)(t.td,{children:["High 32 bits of the chunk blob offset (",(0,s.jsx)(t.code,{children:"c_off"}),") within the ",(0,s.jsx)(t.strong,{children:"segment member payload"})]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"right"},children:(0,s.jsx)(t.code,{children:"8..12"})}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"4"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"u32"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"len"})}),(0,s.jsxs)(t.td,{children:["Length in bytes of the chunk blob (",(0,s.jsx)(t.code,{children:"c_len"}),") stored in the segment member"]})]})]})]}),"\n",(0,s.jsx)(t.p,{children:"So why would you compress the chunks? It's clearly not to be able to store more chunks into each segments because from the metadata we have, the segment boundaries are stable and we just benefit from smaller members. The main reason is probably to lower disk I/O when performing data read from disk to reconstruct a chunk in memory."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"alt text",src:n(940).A+"",title:"Map target dictionnary",width:"2208",height:"2257"})}),"\n",(0,s.jsx)(t.h2,{id:"how-to-read-data",children:"How to read data"}),"\n",(0,s.jsx)(t.p,{children:"At this point, we know the container is Zip64, and that MacQuisition\u2019s AFF4 differs in two key places:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"The map is a packed binary array (28-byte records), not a line-based text map"}),"\n",(0,s.jsx)(t.li,{children:"The data is stored as LZ4-compressed chunks inside segment members, with a per-segment .index file to locate each compressed chunk"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"So reading bytes can happen in the following order: virtual offset \u2192 map interval \u2192 target stream offset \u2192 segment + chunk \u2192 (offset,len) via index \u2192 LZ4 decode \u2192 slice."}),"\n",(0,s.jsxs)(t.p,{children:["In order to implement the exhume_body aff4 support, I first needed to parse the Zip64 central directory and build a dictionary of ",(0,s.jsx)(t.code,{children:"member name \u2192 {header offset; sizes; zip compression method}"}),". Not going into details on how to parse a Zip64 archive but just note that I am using it constantly to fetch information.turtle, the map members, segment members, and the per-segment .index files."]}),"\n",(0,s.jsx)(t.p,{children:"Then, from the Turtle RDF metadata, we extract the values that drive all addressing math:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"image_size"}),"\n",(0,s.jsx)(t.li,{children:"chunk_size"}),"\n",(0,s.jsx)(t.li,{children:"chunks_in_segment"}),"\n",(0,s.jsx)(t.li,{children:"compressionMethod (here: LZ4)"}),"\n",(0,s.jsx)(t.li,{children:"the URNs/base paths for the map object and the data stream"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"As mentioned in my previous observations, Cellebrite/MacQuisition stores two adjacent map members:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:".../idx \u2192 NUL-separated string table of target URIs"}),"\n",(0,s.jsxs)(t.li,{children:[".../map \u2192 packed 28-byte records (LE): (virtual_offset",":u64",", extent_len",":u64",", target_offset",":u64",", target_index",":u32",")"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"I'm turning these into an in-memory interval list:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"each interval maps a virtual range to (target_uri, target_offset)"}),"\n",(0,s.jsx)(t.li,{children:"sort by virtual_offset"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"reading-n-bytes-at-virtual-offset-v",children:"Reading N bytes at virtual offset V"}),"\n",(0,s.jsx)(t.p,{children:"The following pseudo-code algorithm is a summary of the actions performed to read N bytes at a virtual offset V."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"find which interval covers the current position (binary search)"}),"\n",(0,s.jsx)(t.li,{children:"if no interval: it\u2019s a hole \u2192 zero-fill"}),"\n",(0,s.jsxs)(t.li,{children:["if interval found:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"compute the logical offset inside the target stream:"}),"\n",(0,s.jsx)(t.li,{children:"logical_off = interval.target_offset + (pos - interval.virtual_offset)."}),"\n",(0,s.jsx)(t.li,{children:"fetch bytes from the target stream at logical_off (next section)."}),"\n",(0,s.jsx)(t.li,{children:"repeat until the request is satisfied."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h1,{id:"integration-to-the-exhume-toolkit",children:"Integration to the exhume Toolkit"}),"\n",(0,s.jsx)(t.p,{children:"Well, the final result is that exhume_body now supports aff4 as a new format and therefore all of the exhume_modules above (like exhume_filesystem, exhume_partitions, ...)."}),"\n",(0,s.jsx)(t.p,{children:"In order to test the implementation, you can perform the following:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"cargo install exhume_body\nexhume_body -b /PATH/TO/IMAGE.aff4 -f aff4 -s 512 -offset 0x0\n"})}),"\n",(0,s.jsx)(t.p,{children:"Example output:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-raw",children:" Processing the file '/PATH/TO/IMAGE.aff4' in 'aff4' format...\nZip64 EOCD Record located at: 0xa0344ac91\nCentral Directory Total Entries: 0xc91\nCentral Directory Size: 0x602c2\nCentral Directory: 3217 entries starting at 0xa033ea9cf\nMetadata: size                     = 994662584320\nMetadata: stored                   = aff4://78a06441-793b-425d-8952-a3fff45058d1\nMetadata: chunkSize                = 32768\nMetadata: chunksInSegment          = 1024\nMetadata: compressionMethod        = https://code.google.com/p/lz4/\nMetadata: hash                     = 1430c174c043522ed31c52896c1effb597150437\nMetadata: hash                     = a91b7434416c73226fb348ce43808d1c\nMetadata: size                     = 53861023744\nMetadata: stored                   = aff4://78a06441-793b-425d-8952-a3fff45058d1\nMetadata: blockCount               = 242837545\nMetadata: blockSize                = 4096\nMetadata: dataStream               = aff4://1ddcf287-f499-492a-ab06-7edec982b094\nMetadata: size                     = 994662584320\nMetadata: APFSContainerType        = https://blackbagtech.com/aff4/Schema#APFST2ContainerType\nMetadata: ContainsExtents          = true\nMetadata: ContainsUnallocated      = false\nMetadata: integrityStream          = aff4://1ddcf287-f499-492a-ab06-7edec982b094/data\n--- Parsing Binary Map Stream: aff4%3A%2F%2F1ddcf287-f499-492a-ab06-7edec982b094/map ---\nUsing idx table member: aff4%3A%2F%2F1ddcf287-f499-492a-ab06-7edec982b094/idx\nidx table contains 1 target strings\nBuilt 81020 merged intervals. First v_off=0x0\n ------------------------------------------------------------\n Selected format: AFF4 / AFF4-L\n Description: AFF4 ImageStream (Zip volume).\n Sector size: 512\n Evidence : /PATH/TO/IMAGE.aff4\nAFF4 image_size=0xe796829000, chunk_size=0x8000, chunks_in_segment=1024, compression=Lz4, intervals=81020\n00000000: efbf bdef bfbd efbf bdef bfbd efbf bd3f  ...............?\n00000010: 7001 0000 0000 0000 0073 efbf bd00 0000  p........s......\n00000020: 0000 0001 0000 efbf bd00 0000 004e 5853  .............NXS\n00000030: 4200 1000 0029 6879 0e00 0000 0000 0000  B....)hy........\n00000040: 0000 0000 0000 0000 0000 0000 0002 0000  ................\n00000050: 0000 0000 00ef bfbd 18ef bfbd efbf bdef  ................\n00000060: bfbd efbf bd40 0eef bfbd db85 7266 c6ab  .....@......rf..\n00000070: 69ef bfbd 4704 0000 0000 0074 efbf bd00  i...G......t....\n00000080: 0000 0000 0018 0100 005c 6c00 0001 0000  .........\\l.....\n00000090: 0000 0000 0019 0100 0000 0000 00ef bfbd  ................\n000000a0: 0000 0062 3700 00ef bfbd 0000 0002 0000  ...b7...........\n000000b0: 005d 3700 0005 0000 0000 0400 0000 0000  .]7.............\n000000c0: 00ef bfbd efbf bd11 0000 0000 0001 0400  ................\n000000d0: 0000 0000 0000 0000 0064 0000 0002 0400  .........d......\n000000e0: 0000 0000 0006 0400 0000 0000 001b 0500  ................\n000000f0: 0000 0000 001d 0500 0000 0000 001f 0500  ................\n00000100: 0000 0000 0021 0500 0000 0000 0001 0604  .....!..........\n00000110: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000120: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000130: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000140: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000150: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000160: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000170: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000180: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000190: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001c0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001d0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001e0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000001f0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000200: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000210: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000220: 0000 0000 000a                           ......\n"})}),"\n",(0,s.jsx)(t.h1,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(t.p,{children:"Well, this journey was painful. But now I can read MacOs MacQuisitions and begin developing the Exhume APFS module, which was the original objective for the Thanatology project."}),"\n",(0,s.jsxs)(t.p,{children:["My implementation HAS TO BE CONSIDERED AS VERY SPECIFC to the Cellebrite/MacQuisition AFF4 images for now until I put my hands on more images. Feel free to test it, raise any issues you might find on Github or on the dedicated ",(0,s.jsx)(t.a,{href:"https://discord.com/invite/AqkYgR5HEg",children:"Discord Server"}),"."]})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},7975:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/6-5ea62ba33925768e6c0cef08feea1364.png"},8360:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/1-53ac63b335e67d7d970e39ce5f5fe78d.png"},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(6540);const s={},a=i.createContext(s);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:t},e.children)}},9940:e=>{e.exports=JSON.parse('{"permalink":"/blog/exhume-aff4","source":"@site/blog/2026-02-03-aff4/index.md","title":"\ud83d\udd26 Debunking the Cellebrite (MacQuisition) Advanced Forensics File Format Version 4 (AFF4) implementation","description":"In the objective of implementing the modern Apple File System (APFS) module of the exhume toolkit, a test disk image from a recent macOS system was required. In practice, acquiring physical data from modern Apple hardware (especially with T2 / security constraints) quickly narrows the tooling landscape, and Cellebrite BlackLight / MacQuisition seems to be the default choice.","date":"2026-02-03T00:00:00.000Z","tags":[{"inline":true,"label":"Thanatology","permalink":"/blog/tags/thanatology"},{"inline":true,"label":"Exhume","permalink":"/blog/tags/exhume"},{"inline":true,"label":"Digital Forensics","permalink":"/blog/tags/digital-forensics"},{"inline":true,"label":"AFF4","permalink":"/blog/tags/aff-4"}],"readingTime":14.71,"hasTruncateMarker":true,"authors":[{"name":"k1nd0ne","title":"Digital Forensics Spiderman","url":"https://github.com/k1n0ne","page":{"permalink":"/blog/authors/k-1-nd-0-ne"},"socials":{"x":"https://x.com/k1nd0ne","github":"https://github.com/k1nd0ne","bluesky":"https://bsky.app/profile/k1nd0ne.bsky.social"},"imageURL":"https://avatars.githubusercontent.com/u/27780432?v=4","key":"k1nd0ne"}],"frontMatter":{"slug":"exhume-aff4","title":"\ud83d\udd26 Debunking the Cellebrite (MacQuisition) Advanced Forensics File Format Version 4 (AFF4) implementation","authors":["k1nd0ne"],"tags":["Thanatology","Exhume","Digital Forensics","AFF4"],"draft":false},"unlisted":false,"nextItem":{"title":"\ud83c\udf8a Thanatology Project - 2025 wrap up and goals","permalink":"/blog/thanatology-2025"}}')}}]);
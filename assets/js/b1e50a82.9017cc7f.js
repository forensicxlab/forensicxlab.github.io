"use strict";(self.webpackChunkexhume=self.webpackChunkexhume||[]).push([[821],{585:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/1-7a939b608e6c8f0b9b010d3f93415301.png"},758:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/6-454e2ad92c136e89a30f63e22005df0b.png"},1174:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>h});var s=n(4777),i=n(4848),a=n(8453);const r={slug:"ewf",title:"\ud83d\udd26 Debunking the Expert Witness Compression Format (EWF)",authors:["k1nd0ne"],tags:["EWF","Digital Forensics"]},o=void 0,c={authorsImageUrls:[void 0]},h=[{value:"Filesystem layers of abstraction",id:"filesystem-layers-of-abstraction",level:2},{value:"The Expert Witness Compression Format",id:"the-expert-witness-compression-format",level:2},{value:"The segments",id:"the-segments",level:3},{value:"The EWF file Header and Sections",id:"the-ewf-file-header-and-sections",level:4},{value:"The segment file Header",id:"the-segment-file-header",level:4},{value:"The sections",id:"the-sections",level:4},{value:"Parsing the EWF Segments",id:"parsing-the-ewf-segments",level:3},{value:"Step 1: Parsing all the useful metadata from each segment.",id:"step-1-parsing-all-the-useful-metadata-from-each-segment",level:4},{value:"Step 2: Read an arbitrary chunk.",id:"step-2-read-an-arbitrary-chunk",level:4},{value:"Step 3: Create a standard read",id:"step-3-create-a-standard-read",level:4},{value:"Proof of concept",id:"proof-of-concept",level:2},{value:"Conclusion",id:"conclusion",level:2}];function l(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",section:"section",strong:"strong",sup:"sup",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"As a digital forensic expert, proving the authenticity and reliability of a forensic image in court is essential. Indeed, the integrity of the data needs to be maintained during the imaging process, preventing any accidental or intentional modification of the data.\nThe Expert Witness Compression Format (EWF) provides a way to store metadata about the image, such as the source device, imaging tool, checksums, signatures, and other relevant information about the acquired media. This imaging format main feature is its compression capability thus reducing the size of the resulting image file. Compression allows for faster analysis of the data and reduces storage requirements.\nThis article is meant to vulgarize the structures behind an EWF Segment. The reader will discover the main algorithms to use in order to be able to read and seek inside such image format. Finally, a proof of concept writen in rust will be shared to the reader."}),"\n",(0,i.jsx)(t.h2,{id:"filesystem-layers-of-abstraction",children:"Filesystem layers of abstraction"}),"\n",(0,i.jsx)(t.p,{children:"Before getting right into the main subject of this article, it is important to learn or get a little reminder about the filesystem concepts, vocabulary, and the underlying layers of abstractions.\nLet us take the Unix filesystem concept as an example. Below is a vulgarized representation of the main layers of abstraction."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(585).A+"",title:"Filesystem layout",width:"1198",height:"721"})}),"\n",(0,i.jsx)(t.p,{children:"A storage medium (hard drive, SSD, \u2026) have the necessary set of electronics to create an abstraction of the Logical Block Addressing. It can be viewed as contiguous sequence of sectors. A sector is the smallest accessible unit on a drive (typically 512 bytes for disk drives).  It is possible to create a group multiple sectors and form a block.  Blocks are the smallest accessible units on a filesystem.  Each filesystem type can have their own concepts to represents files, directories, hardware devices etc...\nThe exploitation system is supplying the abstraction of those human friendly concepts via the kernel to perform various actions on the filesystem (read, write, seek...)."}),"\n",(0,i.jsx)(t.p,{children:"Digital forensics is performed on a copy of the media to be investigated. This can be done with various tools (FTK Imager, EnCase, dd, Falcon, others\u2026) and produce an image that can have various format (raw, img, ewf, vmdk, vdi\u2026) to be analyzed later without performing the investigation on the original media."}),"\n",(0,i.jsx)(t.p,{children:"From a forensics perspective, when a storage media is acquired, the investigator needs to find a way to emulate all the necessary abstraction layers in order to extract specific artifacts usefull to an investigation without tempering with the data. Forensics tools are providing such abstraction and capabilities. Most of those tools support different image format. One of these formats is well known and largely used: the Expert Witness Compressing Format (EWF)."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(9874).A+"",title:"Filesystem abstraction",width:"1878",height:"1338"})}),"\n",(0,i.jsx)(t.h2,{id:"the-expert-witness-compression-format",children:"The Expert Witness Compression Format"}),"\n",(0,i.jsxs)(t.p,{children:["The Expert Witness Compression Format (EWF) is a forensic image output format created by the ASRDATA company. It can be used to create a bit-by-bit copy of a digital device. It includes both data and metadata, such as the partition table and other information about the device. EWF is designed to maintain the integrity of the original data and can be compressed to reduce storage requirements. It is widely used to preserve evidence for analysis and investigation both by law enforcement, digital forensics and incident response companies. This format is not so easy to understand because it is a proprietary file format, thus the purpose of this blog article. Luckily, the opensource community provide a C library and a nice documentation about this file format ",(0,i.jsx)(t.sup,{children:(0,i.jsx)(t.a,{href:"#user-content-fn-1-ff8942",id:"user-content-fnref-1-ff8942","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),". Let\u2019s try to have a nice mental representation of the components of an EWF image."]}),"\n",(0,i.jsx)(t.h3,{id:"the-segments",children:"The segments"}),"\n",(0,i.jsxs)(t.p,{children:["An EWF image can be divided into multiple segment files (there can also be a unique segment file). Those segments files have a consecutive extension system: Starting from \u201cE01\u201d to \u201cE99\u201d, then in alphabetical order from \u201cEAA\u201d to \u201cZZZ\u201d. Dividing a large sized media evidence source into multiple segments is a great way to prevent a large and unique raw output file that can sometime creates problems on some filesystem. Each segment file is composed of a ",(0,i.jsx)(t.strong,{children:"Header"})," and multiple ",(0,i.jsx)(t.strong,{children:"Sections"}),"."]}),"\n",(0,i.jsx)(t.h4,{id:"the-ewf-file-header-and-sections",children:"The EWF file Header and Sections"}),"\n",(0,i.jsx)(t.p,{children:"Let\u2019s now dive into the components of a EWF segment file."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(4091).A+"",title:"EWF structure",width:"1490",height:"843"})}),"\n",(0,i.jsxs)(t.p,{children:["The EWF is storing the source evidence image\u2019s sectors inside ",(0,i.jsx)(t.strong,{children:"chunks"}),". A chunk is just a group of sectors. There is a finite number of chunks per segments. Therefore, the information about the sectors and chunks needs to be known if we want to read them."]}),"\n",(0,i.jsx)(t.h4,{id:"the-segment-file-header",children:"The segment file Header"}),"\n",(0,i.jsxs)(t.p,{children:["Each segment file has a ",(0,i.jsx)(t.strong,{children:"Header"})," (do not confuse the ",(0,i.jsx)(t.strong,{children:"segment file header"})," with the ",(0,i.jsx)(t.strong,{children:"section header"})," described later). The file header contains a signature (or a magic number) of 8 bytes that attest of its format:"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(2436).A+"",title:"Header",width:"1108",height:"636"})}),"\n",(0,i.jsx)(t.p,{children:"In this example, the signature is: \u201cEVF\\0x09\\0x0d\\0x0a\\0xff\\0x00\u201d"}),"\n",(0,i.jsxs)(t.p,{children:["The file header also contains the information about the ",(0,i.jsx)(t.strong,{children:"first section offset"})," and the segment number."]}),"\n",(0,i.jsx)(t.h4,{id:"the-sections",children:"The sections"}),"\n",(0,i.jsx)(t.p,{children:"The sections are the metadata of the image used by the tools to be able to read the evidence sectors and get other various information about the acquired evidence (checksums, acquisition tool used, timestamps etc\u2026). Each section starts with metadata describing itself:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Its type (header, volume, \u2026)"}),"\n",(0,i.jsx)(t.li,{children:"Its size"}),"\n",(0,i.jsx)(t.li,{children:"The next section offset"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Here is what important information you can extract from each section:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"The header section -"})," Not to be confused with the segment file header described earlier, it contains information about the acquired media (case number, Evidence Number, Examiner name, etc.). Each acquisition tools have their own way of describing what information reside in this section."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"The \u201cvolume\u201d or \u201cdisk\u201d section \u2013"})," It contains critical information about the sectors and the chunks of the acquired media that will help the investigator to parse the EWF file like the chunk count, the size of a chunk, the size of a sector, the number of sectors per chunk."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"The sector section \u2013"})," It contains the actual chunks of the acquired evidence. Now, the main advantage about EWF is that some of the chunks can be compressed to gain space on the destination storage using the zlib compression algorithm. Therefore, we need to know what the offsets of each chunk are and if it is compressed chunk or not."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"The table section \u2013"})," This section is like a table of pointers that will tell the investigator where to find each chunk and if it is compressed. The most significant bit (MSB) of each pointer indicates if the chunk is compressed (1) or uncompressed (0)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"The \u201cend\u201d or \u201cnext\u201d section \u2013"})," The \u201cend\u201c section indicates that this segment file was the last one. However, the \u201cnext\u201d section indicates that there is another segment to parse."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["You can now understand better the image showed at the beginning. To have more details about each section, the libewf project is providing a good documentation ",(0,i.jsx)(t.sup,{children:(0,i.jsx)(t.a,{href:"#user-content-fn-2-ff8942",id:"user-content-fnref-2-ff8942","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"2"})}),"."]}),"\n",(0,i.jsx)(t.h3,{id:"parsing-the-ewf-segments",children:"Parsing the EWF Segments"}),"\n",(0,i.jsx)(t.p,{children:"Now that you have a better understanding of this file format, you want to be able to write a code to create the abstraction layer needed to read data like a standard disk and beginning the extraction of evidence."}),"\n",(0,i.jsx)(t.h4,{id:"step-1-parsing-all-the-useful-metadata-from-each-segment",children:"Step 1: Parsing all the useful metadata from each segment."}),"\n",(0,i.jsx)(t.p,{children:"First, we want to be able to read chunks, we first need to extract all the necessary metadata about those chunks from each segment. To hold all the important metadata, we can create multiple structures to store them. Here is an example of what you can do."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(2381).A+"",title:"EWF structure",width:"1421",height:"896"})}),"\n",(0,i.jsx)(t.p,{children:"Here, the purple color corresponds to a Structure or an Object. The red color represents an HashMap or a Dictionary with a key and a value. The blue color is a vector. You\u2019ll notice that we have created the structures representing the different headers and sections of an EWF Segment. Our main goal is:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"To know where all the segment file descriptors are. (segments)"}),"\n",(0,i.jsx)(t.li,{children:"To store all the chunk for each segment (chunks)."}),"\n",(0,i.jsx)(t.li,{children:"To store all the end of sector offset for each segment (end_of_sectors)."}),"\n",(0,i.jsx)(t.li,{children:"To know what is the current chunk that the EWF structure points to (CachedChunk).\nTo understand better here are the structure definitions of a Chunk and a CachedChunk:"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(758).A+"",title:"Chunk structure",width:"1094",height:"686"})}),"\n",(0,i.jsx)(t.p,{children:"To parse a segment here is a pseudo-code algorithm:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'Algorithm: parse_segment\nParameters: self: The EWF Structure, file: the current segment.\nReturn value: EwfSegment filled with all the information about the chunks\n\nBegin:\n\t\t// Parsing EWF Header\n    self.ewf_header <- new EwfHeader(file)\n    current_offset <- 0xd // We place our self just after the EWFHeader.\n    ewf_section_descriptor_size <- 0x4c\n    extracted_chunks <- []\n\n    begin loop:\n        // Parsing EWF section descriptor\n        section <- new EwfSectionDescriptor(file, current_offset)\n        section_offset <- section.next_section_offset\n        section_size <- section.section_size\n        section_type <- section.section_type_def\n        self.sections.push(section) // Save the section into a vector\n\n        // Saving header information\n        if section_type == "header" or section_type == "header2":\n            self.header <- new EwfHeaderSection(file, current_offset+ewf_section_descriptor_size, self.sections.last())\n\n        // Saving volume information\n        if section_type == "disk" or section_type == "volume":\n            self.volume <- new EwfVolumeSection(file, current_offset+ewf_section_descriptor_size)\n\n        // Extracting chunks from table section\n        if section_type == "table":\n            extracted_chunks.extend(self.parse_table(&file, current_offset+ewf_section_descriptor_size)) //We save our chunks structure.\n\n        // Saving end of sectors information\n        if section_type == "sectors":\n            self.end_of_sectors.insert(self.ewf_header.segment_number, current_offset + section_size)\n\n        // Checking if the current section is done\n        if current_offset == section_offset or section_type == "done":\n            break\n\n        // Updating the offset to go throught the segment file.\n        current_offset <- section_offset\n    end loop\n    // Saving segment and extracted chunks information\n    self.segments.push(file)\n    self.chunks.insert(self.ewf_header.segment_number, extracted_chunks)\n    return self\nEnd\n'})}),"\n",(0,i.jsx)(t.p,{children:"Notice that this function is calling other parsing functions and data structures that I did not describe in pseudo-code. The main goal is to understand the main parsing routine."}),"\n",(0,i.jsx)(t.h4,{id:"step-2-read-an-arbitrary-chunk",children:"Step 2: Read an arbitrary chunk."}),"\n",(0,i.jsxs)(t.p,{children:["Now that we have save all our chunks, we can create a function to read the chunk number ",(0,i.jsx)(t.strong,{children:"X"})," from the given segment number ",(0,i.jsx)(t.strong,{children:"Y"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"Reading a chunk includes checking if it is a compressed chunk. And if so, decompressing its data before."}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"To read the data from a chunk number in a segment file here are the steps to follow :"}),"\n",(0,i.jsx)(t.li,{children:"Check if the given chunk number is valid for the given segment using the \u201cchunks\u201d dictionary in our EWF structure. If not, it raises an error."}),"\n",(0,i.jsx)(t.li,{children:"Use the following variables:"}),"\n"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"data: An empty buffer of bytes to store the read data."}),"\n",(0,i.jsx)(t.li,{children:"chunk: A reference to the chunk object in the segment."}),"\n",(0,i.jsx)(t.li,{children:"start_offset: The starting position in the segment where the chunk data is located."}),"\n",(0,i.jsx)(t.li,{children:"end_offset: The ending position in the segment where the chunk data is located (for compressed chunks)."}),"\n"]}),"\n",(0,i.jsxs)(t.ol,{start:"4",children:["\n",(0,i.jsx)(t.li,{children:"Seek to the starting position of the chunk data in the segment."}),"\n",(0,i.jsx)(t.li,{children:"If the chunk is not compressed, read data from the segment into a buffer."}),"\n",(0,i.jsxs)(t.li,{children:["If the chunk is compressed, decode the compressed data using Zlib ",(0,i.jsx)(t.sup,{children:(0,i.jsx)(t.a,{href:"#user-content-fn-4-ff8942",id:"user-content-fnref-4-ff8942","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"3"})})," and store the result in the data buffer."]}),"\n",(0,i.jsx)(t.li,{children:"Return the data buffer containing the chunk data."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"We can now read the data from any chunk number in a given segment!"}),"\n",(0,i.jsx)(t.h4,{id:"step-3-create-a-standard-read",children:"Step 3: Create a standard read"}),"\n",(0,i.jsxs)(t.p,{children:["Now the last step is to create a read function to imitate the traditional read system call ",(0,i.jsx)(t.sup,{children:(0,i.jsx)(t.a,{href:"#user-content-fn-3-ff8942",id:"user-content-fnref-3-ff8942","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"4"})})," on a POSIX system. To perform this task here are the steps for a given number of bytes to read:"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Check if there is any cached chunk data available. If not, read the first chunk of the first segment and set it as the cached chunk data."}),"\n",(0,i.jsx)(t.li,{children:"Loop until the size is zero."}),"\n",(0,i.jsx)(t.li,{children:"If the remaining size of the data to be read is less than or equal to the remaining data in the cached chunk, update the buffer with the remaining data. Then update the cached chunk pointer and size."}),"\n",(0,i.jsx)(t.li,{children:"If the remaining size is greater than the remaining cached chunk data, update the buffer with all the remaining cached chunk data and calculate the remaining size of the data to be read."}),"\n",(0,i.jsx)(t.li,{children:"Check if there are more chunks to be read or if the end of the segments has been reached. If there are more chunks, get the next chunk number and read that chunk's data."}),"\n",(0,i.jsx)(t.li,{children:"Otherwise, return the buffer that has been read so far (nothing more to read)."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"proof-of-concept",children:"Proof of concept"}),"\n",(0,i.jsxs)(t.p,{children:["Now that we have finished the theorical part, I am sharing to you a proof of concept written in rust. The code can be found here: ",(0,i.jsx)(t.a,{href:"https://github.com/forensicxlab/EWF",children:"https://github.com/forensicxlab/EWF"})]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(4824).A+"",title:"POC",width:"1034",height:"464"})}),"\n",(0,i.jsx)(t.p,{children:"This code will show you all the important metadata about the parsed segments. It is capable of:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Reading and seeking through the sectors of an EWF image."}),"\n",(0,i.jsx)(t.li,{children:"Parsing the MBR."}),"\n",(0,i.jsx)(t.li,{children:"Calculate the original media signature (MD5 of all the sectors)."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsxs)(t.p,{children:["To conclude this blogpost, we were able to create the abstraction layer needed to read an EWF image. We can now identify partitions and create other abstraction layer to read files, reconstruct a system tree etc\u2026 This can be the subject of future blogposts. Do not hesitate to reach me at ",(0,i.jsx)(t.a,{href:"mailto:felix.guyard@forensicxlab.com",children:"felix.guyard@forensicxlab.com"})," to make this article better."]}),"\n","\n",(0,i.jsxs)(t.section,{"data-footnotes":!0,className:"footnotes",children:[(0,i.jsx)(t.h2,{className:"sr-only",id:"footnote-label",children:"Footnotes"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{id:"user-content-fn-1-ff8942",children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://github.com/libyal/libewf/blob/main/documentation/Expert%20Witness%20Compression%20Format%20(EWF).asciidoc",children:"https://github.com/libyal/libewf/blob/main/documentation/Expert%20Witness%20Compression%20Format%20(EWF).asciidoc"})," ",(0,i.jsx)(t.a,{href:"#user-content-fnref-1-ff8942","data-footnote-backref":"","aria-label":"Back to reference 1",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{id:"user-content-fn-2-ff8942",children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://github.com/libyal/libewf",children:"https://github.com/libyal/libewf"})," ",(0,i.jsx)(t.a,{href:"#user-content-fnref-2-ff8942","data-footnote-backref":"","aria-label":"Back to reference 2",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{id:"user-content-fn-4-ff8942",children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.zlib.net/",children:"https://www.zlib.net/"})," ",(0,i.jsx)(t.a,{href:"#user-content-fnref-4-ff8942","data-footnote-backref":"","aria-label":"Back to reference 3",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{id:"user-content-fn-3-ff8942",children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Read_(system_call)",children:"https://en.wikipedia.org/wiki/Read_(system_call)"})," ",(0,i.jsx)(t.a,{href:"#user-content-fnref-3-ff8942","data-footnote-backref":"","aria-label":"Back to reference 4",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},2381:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/5-92d8558c343bb21817ff54253852bcf9.png"},2436:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/4-8f3978b8f737aaa54a501a75624be5a3.png"},4091:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/3-a08894ef23d4821517f6987ecdfe9c8f.png"},4777:e=>{e.exports=JSON.parse('{"permalink":"/blog/ewf","source":"@site/blog/2023-05-11-ewf/index.md","title":"\ud83d\udd26 Debunking the Expert Witness Compression Format (EWF)","description":"As a digital forensic expert, proving the authenticity and reliability of a forensic image in court is essential. Indeed, the integrity of the data needs to be maintained during the imaging process, preventing any accidental or intentional modification of the data.","date":"2023-05-11T00:00:00.000Z","tags":[{"inline":true,"label":"EWF","permalink":"/blog/tags/ewf"},{"inline":true,"label":"Digital Forensics","permalink":"/blog/tags/digital-forensics"}],"readingTime":10.9,"hasTruncateMarker":true,"authors":[{"name":"k1nd0ne","title":"Digital Forensics Spiderman","url":"https://github.com/k1n0ne","page":{"permalink":"/blog/authors/k-1-nd-0-ne"},"socials":{"x":"https://x.com/k1nd0ne","github":"https://github.com/k1nd0ne"},"imageURL":"https://avatars.githubusercontent.com/u/27780432?v=4","key":"k1nd0ne"}],"frontMatter":{"slug":"ewf","title":"\ud83d\udd26 Debunking the Expert Witness Compression Format (EWF)","authors":["k1nd0ne"],"tags":["EWF","Digital Forensics"]},"unlisted":false,"prevItem":{"title":"\ud83d\udce6 Volatility3 Windows Plugin - KeePass","permalink":"/blog/keepass"},"nextItem":{"title":"\ud83e\uddec Malware Analysis with VISION-ProcMon","permalink":"/blog/vision"}}')},4824:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/8-195c0769fda1a529bb0a81405c89676a.png"},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var s=n(6540);const i={},a=s.createContext(i);function r(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:t},e.children)}},9874:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/2-f5aa868db1de4b2b4395bdc65c95f35b.png"}}]);